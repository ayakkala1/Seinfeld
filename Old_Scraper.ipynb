{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seinfeld Scritp Scraper \n",
    "\n",
    "### URL : http://www.seinology.com/scripts.shtml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "from json import dump,loads\n",
    "from requests import get\n",
    "import json\n",
    "from re import sub\n",
    "from dateutil import parser as dateparser\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_script(url):\n",
    "    possible_scripts = []\n",
    "    r = urllib.request.urlopen(url)\n",
    "    parser = html.fromstring(r.read())\n",
    "    for i in parser.xpath('//*[@id=\"content\"]/p'):\n",
    "        if (not(\"Looking for  a great gift idea for the h\" in str(i.text_content())) and str(i.text_content()) != \"\" and len(str(i.text_content())) > 1):\n",
    "            possible_scripts.append(str(i.text_content()))\n",
    "    try:\n",
    "        possible_scripts.append(str(parser.xpath(\"//pre//text()\")))\n",
    "    except:\n",
    "        x = 1\n",
    "    return possible_scripts\n",
    "\n",
    "def extract_max(a_list):\n",
    "    try:\n",
    "        return \" \".join(a_list)\n",
    "    except:\n",
    "        max_len = \"\"\n",
    "        for i in a_list:\n",
    "            if len(max_len) < len(i):\n",
    "                max_len = i\n",
    "        return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get(\"http://www.seinfeldscripts.com/seinfeld-scripts.html\")\n",
    "cleaned_response = response.text.replace('\\x00', \"\")\n",
    "                                         \n",
    "parser = html.fromstring(cleaned_response)\n",
    "                                         \n",
    "for i in parser.xpath('//table'):\n",
    "    if i.attrib['width'] == \"670\":\n",
    "        table_of_seasons = i  \n",
    "                                         \n",
    "tables = table_of_seasons.xpath('//table')\n",
    "\n",
    "seasons = []\n",
    "holder = \"\"\n",
    "for i in tables[2:]:\n",
    "    season = {}\n",
    "    episodes = []\n",
    "    if len(i.xpath(\".//big//font//b\")) > 0:\n",
    "        season[\"season\"] = i.xpath(\".//big//font//b\")[0].text\n",
    "        holder = i.xpath(\".//big//font//b\")[0].text\n",
    "    else:\n",
    "        if (i.xpath(\".//tr\")[0].xpath(\".//td\")[0].text_content() !=\n",
    "           \"\\xa0\"):\n",
    "            season[\"season\"] = holder\n",
    "            for j in i.xpath(\".//tr\"):\n",
    "                episode = {}\n",
    "                for k in j.xpath(\".//td\"):\n",
    "                    episode[\"name\"] = k.text_content()\n",
    "                for k in j.xpath(\".//td//a\"):\n",
    "                    episode[\"url\"] = k.attrib[\"href\"]\n",
    "                episodes.append(episode)\n",
    "    for j in i.xpath(\".//tr\")[1:]:\n",
    "        episode = {}\n",
    "        for k in j.xpath(\".//td\"):\n",
    "            episode[\"name\"] = k.text_content()\n",
    "        for k in j.xpath(\".//td//a\"):\n",
    "            episode[\"url\"] = k.attrib[\"href\"]\n",
    "        episodes.append(episode)\n",
    "    season[\"episodes\"] = episodes\n",
    "    seasons.append(season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(seasons)\n",
    "df = (df['episodes'].apply(lambda x: pd.Series(x))\n",
    "            .stack()\n",
    "            .reset_index(level=1, drop=True)\n",
    "            .to_frame('episodes')\n",
    "            .join(df[['season']], how='left'))\n",
    "df[[\"name\",\"url\"]] = df.episodes.apply(pd.Series)\n",
    "df = df.drop(\"episodes\",axis=1).reset_index(drop=True)\n",
    "df = df.drop_duplicates().reset_index(drop=True).dropna()\n",
    "df[\"url\"] = df[\"url\"].str.strip()\n",
    "df[\"url\"] = \"http://www.seinfeldscripts.com/\" + df[\"url\"]\n",
    "df[\"season_year\"] = df[\"season\"].str.extract(\"\\(([^\\)]+)\\)\")\n",
    "df[\"season\"] = df[\"season\"].str.extract(\"^(.*?)\\(\")\n",
    "df[\"name\"] = df[\"name\"].str.replace(\"\\n\",\"\")\n",
    "df[\"name\"] = df[\"name\"].str.strip()\n",
    "df[\"date\"] = df[\"name\"].str.extract(\"\\(([^\\)]+)\\)$\")\n",
    "df[\"name\"] = df[\"name\"].str.extract(\"(^(.*?)\\(\\d\\)|.+?(?=\\())\")\n",
    "df[\"script\"] = df[\"url\"].apply(extract_script)\n",
    "df[\"big_script\"] = df[\"script\"].apply(extract_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"seinfeld.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
